{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8cf6101",
   "metadata": {},
   "source": [
    "### DataSet for Text Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04807ff",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e4e0d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b5e068f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_name=\"IMDB Dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c826905",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_data=pd.read_csv(path_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "696dc2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_data.head()   #display first ffive rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a402ffbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_data.shape  #display the shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "510eb8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_d100=movies_data.head(100)  #select first 100 rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "296cf84a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_d100.shape  #display the shape of the new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bf7380",
   "metadata": {},
   "source": [
    "# Apply Data Cleaning Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e8de9e",
   "metadata": {},
   "source": [
    "Only use required Techniques for Data Cleaning according to requirement of LLM and you"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3a52f7",
   "metadata": {},
   "source": [
    "- lowercase(change all upper case into lower case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93e75a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I\\'d laughed at one of Woody\\'s comedies in years (dare I say a decade?). While I\\'ve never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_d100['review'][2]  #display the review of the third movie in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c95c1c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mehboob Alam\\AppData\\Local\\Temp\\ipykernel_11248\\1941570102.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movies_d100['review'] = movies_d100['review'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "# convert to lowercase\n",
    "movies_d100['review'] = movies_d100['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ce15e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. the plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). while some may be disappointed when they realize this is not match point 2: risk addiction, i thought it was proof that woody allen is still fully in control of the style many of us have grown to love.<br /><br />this was the most i\\'d laughed at one of woody\\'s comedies in years (dare i say a decade?). while i\\'ve never been impressed with scarlet johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />this may not be the crown jewel of his career, but it was wittier than \"devil wears prada\" and more interesting than \"superman\" a great comedy to go see with friends.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_d100['review'][2]  #checking it convert into lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfff705",
   "metadata": {},
   "source": [
    "- Remove HTML Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94338e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # regex library\n",
    "def remove_html_tags(text):\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "498760f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take exxample html text\n",
    "html_text = \"<div><h1>This is a <b>sample</b> HTML text.</h1><p>It contains <a href='#'>links</a> and <i>formatting</i> tags.</p></div>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c10f6a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sample HTML text.It contains links and formatting tags.\n"
     ]
    }
   ],
   "source": [
    "after_remove_html=remove_html_tags(html_text)\n",
    "print(after_remove_html)  #display the text after removing html tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05897e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mehboob Alam\\AppData\\Local\\Temp\\ipykernel_11248\\1746602577.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movies_d100['review'] = movies_d100['review'].apply(remove_html_tags)\n"
     ]
    }
   ],
   "source": [
    "# simpily apply the function to the 'review' column\n",
    "movies_d100['review'] = movies_d100['review'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ea5e53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a noble cause, but it\\'s not preachy or boring. it just never gets old, despite my having seen it some 15 or more times in the last 25 years. paul lukas\\' performance brings tears to my eyes, and bette davis, in one of her very few truly sympathetic roles, is a delight. the kids are, as grandma says, more like \"dressed-up midgets\" than children, but that only makes them more fun to watch. and the mother\\'s slow awakening to what\\'s happening in the world and under her own roof is believable and startling. if i had a dozen thumbs, they\\'d all be \"up\" for this movie.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_d100['review'][2]  #check html tags in third movie review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6257f88f",
   "metadata": {},
   "source": [
    "- Remove URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d233a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url_from_text(text):\n",
    "    clean=re.compile(r'http\\S+|www\\S+|https\\S+')\n",
    "    return re.sub(clean, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51210463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This is a sample text with a URL.\n",
      " Visit  for more info.\n"
     ]
    }
   ],
   "source": [
    "urlText=\"http://example.com This is a sample text with a URL.\\n Visit www.example.org for more info.\"\n",
    "print(remove_url_from_text(urlText))  #display the text after removing URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e987bf47",
   "metadata": {},
   "source": [
    "- Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55cddfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string,time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "925d3aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation  #display all punctuation characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb6feaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_punctuations = string.punctuation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9af5a0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    for punctuation in exclude_punctuations:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6181fbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to remove punctuation: 9.335994720458984 miliseconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mehboob Alam\\AppData\\Local\\Temp\\ipykernel_11248\\4145203928.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movies_d100['review'] = movies_d100['review'].apply(remove_punctuation)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()  #start time for measuring performance\n",
    "movies_d100['review'] = movies_d100['review'].apply(remove_punctuation)\n",
    "end_time = time.time()  #end time for measuring performance\n",
    "print(f\"Time taken to remove punctuation: {(end_time - start_time)*1000} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "441d113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation1(text):\n",
    "    return text.translate(str.maketrans('', '', exclude_punctuations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b4e2bffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to remove punctuation: 8.984088897705078 miliseconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mehboob Alam\\AppData\\Local\\Temp\\ipykernel_11248\\2456345622.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movies_d100['review'] = movies_d100['review'].apply(remove_punctuation1)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()  #start time for measuring performance\n",
    "pun_text=\"Hello, world! This is a test: remove punctuation.\"\n",
    "movies_d100['review'] = movies_d100['review'].apply(remove_punctuation1)\n",
    "end_time = time.time()  #end time for measuring performance\n",
    "print(f\"Time taken to remove punctuation: {(end_time - start_time)*1000}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6e86fe",
   "metadata": {},
   "source": [
    "- Remove Short Form of Word with real one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f42dca04",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_words = {\n",
    "    'AFK':'Away From Keyboard',\n",
    "    'ASAP':'As Soon As Possible',\n",
    "    \"FYI\": \"For Your Information\",\n",
    "    \"ASAP\": \"As Soon As Possible\",\n",
    "    \"BRB\": \"Be Right Back\",\n",
    "    \"BTW\": \"By The Way\",\n",
    "    \"OMG\": \"Oh My God\",\n",
    "    \"IMO\": \"In My Opinion\",\n",
    "    \"LOL\": \"Laugh Out Loud\",\n",
    "    \"TTYL\": \"Talk To You Later\",\n",
    "    \"GTG\": \"Got To Go\",\n",
    "    \"TTYT\": \"Talk To You Tomorrow\",\n",
    "    \"IDK\": \"I Don't Know\",\n",
    "    \"TMI\": \"Too Much Information\",\n",
    "    \"IMHO\": \"In My Humble Opinion\",\n",
    "    \"ICYMI\": \"In Case You Missed It\",\n",
    "    \"AFAIK\": \"As Far As I Know\",\n",
    "    \"BTW\": \"By The Way\",\n",
    "    \"FAQ\": \"Frequently Asked Questions\",\n",
    "    \"TGIF\": \"Thank God It's Friday\",\n",
    "    \"FYA\": \"For Your Action\",\n",
    "    \"ICYMI\": \"In Case You Missed It\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2b1e0af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_short_form_with_real_one(text):\n",
    "    for short_form, real_word in chat_words.items():\n",
    "        text = text.replace(short_form, real_word)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b7d80ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Your Information, I will be Away From Keyboard for a while. Talk To You Later!\n"
     ]
    }
   ],
   "source": [
    "text=\"FYI, I will be AFK for a while. TTYL!\"\n",
    "print(remove_short_form_with_real_one(text))  #display the text after replacing short forms with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef37ce6",
   "metadata": {},
   "source": [
    "- Incorrect Spell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ba0cc9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f63e4317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have a dream that one day this nation will rise up and live out the true meaning of its creed.\n"
     ]
    }
   ],
   "source": [
    "incorrect_text = \"I havv a dreem that one day this nation will rise up and live out the true meaning of its creed.\"\n",
    "def correct_spelling(text):\n",
    "    blob = TextBlob(text)\n",
    "    corrected_text = blob.correct()\n",
    "    return str(corrected_text)\n",
    "print(correct_spelling(incorrect_text))  #display the text after correcting spelling mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a235a31b",
   "metadata": {},
   "source": [
    "- Stops Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22ee7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of English stop words: 198\n",
      "Sample stop words: ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been']\n",
      "\n",
      "Original text: This is a sample text with many stop words like the, and, is, a that should be removed\n",
      "After removing stop words: sample text many stop words like the, and, is, removed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fresh import\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as sw\n",
    "\n",
    "# Download stopwords if needed\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "# Get English stop words\n",
    "english_stop_words = set(sw.words('english'))\n",
    "print(f\"Number of English stop words: {len(english_stop_words)}\")\n",
    "print(f\"Sample stop words: {sorted(list(english_stop_words))[:20]}\")\n",
    "\n",
    "# Function to remove stop words from text\n",
    "def remove_stop_words(text):\n",
    "    \"\"\"\n",
    "    Remove English stop words from text\n",
    "    Args:\n",
    "        text (str): Input text string\n",
    "    Returns:\n",
    "        str: Text with stop words removed\n",
    "    \"\"\"\n",
    "    # Split text into words\n",
    "    words = text.split()\n",
    "    # Filter out stop words (case insensitive)\n",
    "    filtered_words = [word for word in words if word.lower() not in english_stop_words]\n",
    "    # Join the remaining words back into text\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Test the function\n",
    "sample_text = \"This is a sample text with many stop words like the, and, is, a that should be removed\"\n",
    "print(f\"\\nOriginal text: {sample_text}\")\n",
    "print(f\"After removing stop words: {remove_stop_words(sample_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4f5e7363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mehboob Alam\\AppData\\Local\\Temp\\ipykernel_11248\\2070816806.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movies_d100['review'] = movies_d100['review'].apply(remove_stop_words)\n"
     ]
    }
   ],
   "source": [
    "movies_d100['review'] = movies_d100['review'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4ce8608d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thought wonderful way spend time hot summer weekend sitting air conditioned theater watching lighthearted comedy plot simplistic dialogue witty characters likable even well bread suspected serial killer may disappointed realize match point 2 risk addiction thought proof woody allen still fully control style many us grown lovethis id laughed one woodys comedies years dare say decade ive never impressed scarlet johanson managed tone sexy image jumped right average spirited young womanthis may crown jewel career wittier devil wears prada interesting superman great comedy go see friends'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_d100['review'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307cde1a",
   "metadata": {},
   "source": [
    "-  Remove Emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2c8f5a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(text):\n",
    "    \"\"\"\n",
    "    Remove emojis from text\n",
    "    Args:\n",
    "        text (str): Input text string\n",
    "        \"\"\"\n",
    "    clean = re.compile(r'[\\U00010000-\\U0010ffff]', flags=re.UNICODE)\n",
    "    return re.sub(clean, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f7f06569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sample text with emojis \n"
     ]
    }
   ],
   "source": [
    "emojis_text = \"This is a sample text with emojis 😊😂👍\"\n",
    "print(remove_emojis(emojis_text))  #display the text after removing emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ba6d47",
   "metadata": {},
   "source": [
    "- Get Meaning of Emoji when i see the feeling of emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8ce95b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sample text with emojis :smiling_face_with_smiling_eyes::face_with_tears_of_joy::thumbs_up:\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "\n",
    "print(emoji.demojize(emojis_text))  #display the text after converting emojis to text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f7ecdc",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687ca214",
   "metadata": {},
   "source": [
    "### 1. Work Level Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d92fc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'sample', 'text', 'to', 'split', 'into', 'words.']\n"
     ]
    }
   ],
   "source": [
    "# worklevel tokenization\n",
    "def split_words(text):\n",
    "    \"\"\"\n",
    "    Split text into words\n",
    "    Args:\n",
    "        text (str): Input text string\n",
    "    Returns:\n",
    "        list: List of words in the text\n",
    "    \"\"\"\n",
    "    return text.split()\n",
    "\n",
    "print(split_words(\"This is a sample text to split into words.\"))  #display the list of words in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "717aa4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'sample', 'text', 'to', 'tokenize', 'using', 'regex']\n"
     ]
    }
   ],
   "source": [
    "#n using regularExpression word level tokenization\n",
    "import re\n",
    "\n",
    "def regex_word_tokenization(text):\n",
    "    \"\"\"\n",
    "    Tokenize text into words using regular expressions\n",
    "    Args:\n",
    "        text (str): Input text string\n",
    "    Returns:\n",
    "        list: List of words in the text\n",
    "    \"\"\"\n",
    "    return re.findall(r'\\b\\w+\\b', text)\n",
    "\n",
    "print(regex_word_tokenization(\"This is a sample text to tokenize using regex.\"))  #display the list of words in the text using regex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dce8e6",
   "metadata": {},
   "source": [
    "### 2. Sentence Level Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3826dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is the first sentence', 'This is the second sentence! Is this the third sentence.']\n"
     ]
    }
   ],
   "source": [
    "# sentence level tokenization \n",
    "def split_sentences(text):\n",
    "    \"\"\"\n",
    "    Split text into sentences\n",
    "    Args:\n",
    "        text (str): Input text string\n",
    "    Returns:\n",
    "        list: List of sentences in the text\n",
    "    \"\"\"\n",
    "    return text.split('. ')  # Split by period followed by space\n",
    "print(split_sentences(\"This is the first sentence. This is the second sentence! Is this the third sentence.\"))  #display the list of sentences in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f993040a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is the first sentence.', 'This is the second sentence!', 'Is this the third sentence?', 'Hello world']\n"
     ]
    }
   ],
   "source": [
    "# using regex for sentence level tokeization for more complex cases\n",
    "def regex_sentence_tokenization(text):\n",
    "    \"\"\"\n",
    "    Tokenize text into sentences using regular expressions\n",
    "    Args:\n",
    "        text (str): Input text string\n",
    "    Returns:\n",
    "        list: List of sentences in the text\n",
    "    \"\"\"\n",
    "    return re.split(r'(?<=[.!?]) +', text)  # Split by punctuation followed by space\n",
    "\n",
    "print(regex_sentence_tokenization(\"This is the first sentence. This is the second sentence! Is this the third sentence? Hello world\"))  #display the list of sentences in the text using regex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548efa95",
   "metadata": {},
   "source": [
    "### 3. Spacy for Tokenizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "333d7ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.system(f'\"{sys.executable}\" -m spacy download en_core_web_sm')\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Example text\n",
    "text = \"This is a sample text to tokenize into words using spaCy.\"\n",
    "\n",
    "def tokenizationofSentneceInWords(text):\n",
    "    \"\"\"\n",
    "    Tokenize text into words using spaCy\n",
    "    Args:\n",
    "        text (str): Input text string\n",
    "    Returns:\n",
    "        list: List of words in the text\n",
    "    \"\"\"\n",
    "    doc = nlp(text)  # Process the text\n",
    "    return [token.text for token in doc]  # Tokenize and return each token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee137143",
   "metadata": {},
   "source": [
    "## Stremmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bf0a9f",
   "metadata": {},
   "source": [
    "### 1. Move word in root form using grammer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55480ab8",
   "metadata": {},
   "source": [
    "- Example root form of played,paying  is play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0dab2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc9382c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps =PorterStemmer()\n",
    "def stem_words(text):\n",
    "    \"\"\"\n",
    "    Stem words in the text using Porter Stemmer\n",
    "    Args:\n",
    "        text (str): Input text string\n",
    "    Returns:\n",
    "        str: Text with stemmed words\n",
    "    \"\"\"\n",
    "    stemmed_words = [ps.stem(word) for word in text.split()]\n",
    "    return ' '.join(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c313ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk walk walk play play'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_words(\"walking walks walked played playing\")  #display the text after stemming the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afa1ad20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the children were play in the playground, run and jump with excitement. their laughter echo across the field as they chase each other, climb the slides, and swung on the swings. some were draw pictur with color chalk, while other were build sandcastl in the sandbox. the teacher watch carefully, make sure everyon wa safe and happy. later, the children gather for stori time, listen attent as the teacher read tale of adventure, friendship, and bravery. after the stories, they discuss the lesson learn and share their own experiences. as the sun began to set, parent arriv to pick up their children, who wave goodby to their friend and promis to meet again the next day. the playground slowli emptied, leav behind memori of joy, learning, and togetherness.\n"
     ]
    }
   ],
   "source": [
    "story=\"\"\" The children were playing in the playground, running and jumping with excitement. Their laughter echoed across the field as they chased each other, climbed the slides, and swung on the swings. Some were drawing pictures with colored chalk, while others were building sandcastles in the sandbox. The teachers watched carefully, making sure everyone was safe and happy. Later, the children gathered for story time, listening attentively as the teacher read tales of adventure, friendship, and bravery. After the stories, they discussed the lessons learned and shared their own experiences. As the sun began to set, parents arrived to pick up their children, who waved goodbye to their friends and promised to meet again the next day. The playground slowly emptied, leaving behind memories of joy, learning, and togetherness.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(stem_words(story))  #display the text after stemming the words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c924856a",
   "metadata": {},
   "source": [
    "### Story: The Tale of the Stemming Wizard\n",
    "\n",
    "Once upon a time, in the land of Textville, there lived a wise wizard named Stemmer. Stemmer had a magical power: he could transform words into their root forms! Whenever villagers brought him words like \"playing\", \"played\", or \"plays\", Stemmer would wave his wand and turn them all into \"play\".\n",
    "\n",
    "This magic helped the villagers organize their library, search for information, and understand stories better. Let's see how Stemmer's magic works in Python using the PorterStemmer!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9ea0a6",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a35f4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Lemmatized Word     \n",
      "The                 The                 \n",
      "children            children            \n",
      "were                be                  \n",
      "playing             play                \n",
      "in                  in                  \n",
      "the                 the                 \n",
      "playground          playground          \n",
      "running             run                 \n",
      "and                 and                 \n",
      "jumping             jump                \n",
      "with                with                \n",
      "excitement          excitement          \n"
     ]
    }
   ],
   "source": [
    "import  nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "sentence = \"The children were playing in the playground, running and jumping with excitement.\"\n",
    "punctionation = '.?:!,;:'\n",
    "sentence_words= tokenizationofSentneceInWords(sentence)\n",
    "\n",
    "for word in sentence_words:\n",
    "    if  word in punctionation:\n",
    "        sentence_words.remove(word)\n",
    "\n",
    "print(\"{0:20}{1:20}\".format(\"Word\", \"Lemmatized Word\"))\n",
    "for word in sentence_words:\n",
    "    lemmatized_word = wordnet_lemmatizer.lemmatize(word,pos='v')\n",
    "    print(\"{0:20}{1:20}\".format(word, lemmatized_word))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e13371",
   "metadata": {},
   "source": [
    "Stemming and Lemmatization is same in working but , in lemmatization the word are readable and meaningful, while stemming may produce non-words or less meaningful forms.\n",
    "\n",
    "Lemmatization is slow and Stemming is fast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f531f197",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
